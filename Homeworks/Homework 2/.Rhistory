lbph = -1.38,
svi = factor("1", levels = levels(cancer$svi)),
lcp = -2.46,
gleason = factor("7", levels = levels(cancer$gleason)),
pgg45 = as.integer(10),
lpsa = 5.14)
rf <- randomForest(lpsa~.,data = cancer, mtry =rf.opt.mtry)
bg <- gbm(lpsa ~ ., data=cancer, distribution="gaussian",
n.trees=ns.opt.n.trees, interaction.depth=3, shrinkage= 0.01)
pred.rf <-  predict(rf,newdata=x.new)
pred.bg <-  predict(bg,newdata=x.new)
pred.rf
pred.bg
pr.raw<- tree_model <- tree(lpsa ~ ., data = cancer)
pr <- prune.tree(tree_model, k = pr.opt.k)
pred.pr <-  predict(pr,newdata=x.new)
pred.pr
# new observation
set.seed(1)
x.new <- data.frame(lcavol = 2.90,
lweight = 3.39,
age = as.integer(52),
lbph = -1.38,
svi = factor("1", levels = levels(cancer$svi)),
lcp = -2.46,
gleason = factor("7", levels = levels(cancer$gleason)),
pgg45 = as.integer(10),
lpsa = 5.14)
rf <- randomForest(lpsa~.,data = cancer, mtry =rf.opt.mtry)
bg <- gbm(lpsa ~ ., data=cancer, distribution="gaussian",
n.trees=ns.opt.n.trees, interaction.depth=3, shrinkage= 0.01)
pr.raw<- tree_model <- tree(lpsa ~ ., data = cancer)
pr <- prune.tree(tree_model, k = pr.opt.k)
pred.rf <-  predict(rf,newdata=x.new)
pred.bg <-  predict(bg,newdata=x.new)
pred.pr <-  predict(pr,newdata=x.new)
pred.rf
pred.bg
pred.pr
set.seed(1)
# new observation
x.new <- data.frame(lcavol = 2.90,
lweight = 3.39,
age = as.integer(52),
lbph = -1.38,
svi = factor("1", levels = levels(cancer$svi)),
lcp = -2.46,
gleason = factor("7", levels = levels(cancer$gleason)),
pgg45 = as.integer(10),
lpsa = 5.14)
# fit a the optimal random forest model
rf <- randomForest(lpsa~.,data = cancer, mtry =rf.opt.mtry)
# take prediction on the new observation
pred.rf <-  predict(rf,newdata=x.new)
print(paste("The model has predicted a level of log prostate antigen of", pred.rf.))
set.seed(1)
# new observation
x.new <- data.frame(lcavol = 2.90,
lweight = 3.39,
age = as.integer(52),
lbph = -1.38,
svi = factor("1", levels = levels(cancer$svi)),
lcp = -2.46,
gleason = factor("7", levels = levels(cancer$gleason)),
pgg45 = as.integer(10),
lpsa = 5.14)
# fit a the optimal random forest model
rf <- randomForest(lpsa~.,data = cancer, mtry =rf.opt.mtry)
# take prediction on the new observation
pred.rf <-  predict(rf,newdata=x.new)
print(paste("The model has predicted a level of log prostate antigen of", pred.rf))
set.seed(1)
# new observation
x.new <- data.frame(lcavol = 2.90,
lweight = 3.39,
age = as.integer(52),
lbph = -1.38,
svi = factor("1", levels = levels(cancer$svi)),
lcp = -2.46,
gleason = factor("7", levels = levels(cancer$gleason)),
pgg45 = as.integer(10),
lpsa = 5.14)
# fit a the optimal random forest model
rf <- randomForest(lpsa~.,data = cancer, mtry =rf.opt.mtry)
# take prediction on the new observation
pred.rf <-  round(predict(rf,newdata=x.new),4)
print(paste("The model has predicted a level of log prostate antigen of", pred.rf))
#| label: plot pruning raw recision tree
#| echo: false
#| fig-cap: "Left: cross-validation for selecting the size; Right: pruned tree  distinguishes patients by cancer volume: above $e^{2.46}$ cm続, below $e^{-0.47}$ cm続, and within the latter group, by prostate weight: above $e^{3.68}$ and below. Predicted PSA levels for these groups are $e^{3.7650} = 43.16$, $e^{0.6017} = 1.82$, $e^{2.7120} = 15.02$, and $e^{2.0330} = 7.63$."
# plot
#op <- par(mfrow=c(1, 2))
op <- par(mfrow=c(1, 2))
plot(cv.cancer$size, cv.cancer$dev, type="b", xlab = "size",ylab = "deviance")
title(main="CV: Deviance vs Size")
points(opt.size, cv.cancer$dev[which.min(cv.cancer$dev)], col = "green",  cex = 2, pch = 20)
plot(prune_cancer)
text(prune_cancer, pretty=0, cex = 0.9)
title(main="Cancer: Pruned tree")
par(op)
#| label: plot pruning raw recision tree
#| echo: false
#| fig-cap: "Left: cross-validation for selecting the size; Right: pruned tree  distinguishes patients by cancer volume: above $e^{2.46}$ cm続, below $e^{-0.47}$ cm続, and within the latter group, by prostate weight: above $e^{3.68}$ and below. Predicted PSA levels for these groups are $e^{3.7650} = 43.16$, $e^{0.6017} = 1.82$, $e^{2.7120} = 15.02$, and $e^{2.0330} = 7.63$."
# plot
#op <- par(mfrow=c(1, 2))
op <- par(mfrow=c(1, 2))
plot(cv.cancer$size, cv.cancer$dev, type="b", xlab = "size",ylab = "deviance")
title(main="CV: Deviance vs Size")
points(opt.size, cv.cancer$dev[which.min(cv.cancer$dev)], col = "green",  cex = 2, pch = 20)
plot(prune_cancer)
text(prune_cancer, pretty=0, cex = 0.9)
title(main="Cancer: Pruned tree")
par(op)
#| label: plt rf
#| echo: false
#| fig-cap: "shows the CV error based on the number of variables used for each split, with a vertical line indicating the optimal **mtry** value. These results suggest selecting a random forest generated by utilizing 500 trees and 5 variables for each split."
# set x axis and y axis values
x_val <- c(1: 7)
# plot
plot(x_val, y= cv.mse.rf, xlab="mtry" , ylab="MSE", type = "b")
abline(v=opt.mrty,col = "red", lty = 2)
points(opt.mrty,min_val_rf, col = "green", cex = 2, pch = 20)
text(opt.mrty,min_val_rf, labels = paste("Min MSE:", min_val_rf), pos = 4, col = "black",cex = 0.9)
title(main="CV: MSE vs mtry")
opt.mrty
set.seed(1)
# create 5 folds
rf_folds = createFolds(cancer$lpsa, k = 5, list = FALSE)
# initialize hyperparameter sequence and mse matrix
v.mrty <- 1:7
rf.mse <- matrix(0, nrow = 5, ncol = 7)
# loop
for(i in 1:5){
# split dataset into training set and test set
cancer_idx = which(rf_folds == i)
cancer_trn = cancer[-cancer_idx,]
cancer_tst = cancer[cancer_idx,]
y_test <- cancer_tst$lpsa
# loop over the hyperparameter values for each fold
for(j in v.mrty){
rf.cancer <- randomForest(lpsa ~ ., data=cancer_trn, mtry=j, importance=TRUE)
pred <- predict(rf.cancer, newdata=cancer_tst)
rf.mse[i, j]<- compute_mse(pred, y_test)
}
}
# compute for each hyperparameter values the cv error
cv.mse.rf <- apply(rf.mse, FUN=mean, MARGIN = 2)
# return the optimal value of the hyperparameter and the lowest cv-error
opt.mrty <-which.min(cv.mse.rf)
min_val_rf <- round(min(cv.mse.rf),4)
opt.mrty
cv.mse.rf
#| echo: false
#| label: fig-plotbg
#| fig-cap: "shows the CV error based on the number of trees used, with a vertical line indicating the optimal **ntrees** value. These results suggest selecting a boosting decision tree utilizing 250 trees, learning rate of 0.01, complexity of 3."
# set x axis and y axis values
x_val <- c(1: 10)
# plot
plot(v.ntrees, y= cv.mse.bg, xlab="n.trees" , ylab="MSE", type = "b")
axis(side = 1, at = v.ntrees, labels = v.ntrees)
abline(v=opt.ntrees,col = "red", lty = 2)
text(opt.ntrees,min_val_bg, labels = paste("Min MSE:", min_val_bg), pos = 4, col = "black", cex = 0.8)
title(main="CV: MSE vs n.trees")
#| echo: true
#| output: false
#| code-overflow: scroll
set.seed(1)
# split the data into 5 folds
cancer_folds = createFolds(cancer$lpsa, k = 5, list = FALSE)
# set the traincontrol
cv_5 = trainControl(method = "cv",
number = 5,
search = "grid")
# collect the predict score got from CV.
predicted_rf = matrix(0, nrow=5, ncol = 1)
predicted_bg = matrix(0, nrow=5, ncol = 1)
predicted_pr = matrix(0, nrow=5, ncol = 1)
# set the grid for hyperparamenters' values
tune_grid_rf <- expand.grid(mtry = 1:7)
tune_grid_gb <- expand.grid(n.trees = seq(50,1000,length=10),interaction.depth = 3,shrinkage = 0.01,n.minobsinnode = 10)
tune_grid_pr <- expand.grid(cp = seq(0.5,10,length=5))
# outer loop
for(i in 1:5){
# split dataset into training set and test set
cancer_idx = which(cancer_folds == i)
cancer_trn = cancer[-cancer_idx,]
cancer_tst = cancer[cancer_idx,]
# inner loop for random forest
def_rf <-  train(
lpsa ~., data = cancer_trn,
method = "rf",
trControl = cv_5,
tuneGrid = tune_grid_rf
)
# collect the predict score based on random forest optimal model
pred <-  predict(def_rf,newdata=cancer_tst)
predicted_rf[i] <- mean((cancer_tst$lpsa - pred)^2)
# inner loop for boosted tree
def_bg <-  train(
lpsa ~., data = cancer_trn,
method = "gbm",
trControl = cv_5,
tuneGrid = tune_grid_gb
)
# collect the predict score based on boosted tree optimal model
pred <-  predict(def_bg,newdata=cancer_tst)
predicted_bg[i] <- mean((cancer_tst$lpsa - pred)^2)
# inner loop for cost-complexity decision tree
def_pr <-  train(
lpsa ~., data = cancer_trn,
method = "rpart",
trControl = cv_5,
tuneGrid = tune_grid_pr
)
# collect the predict score based on ost-complexity decision tree optimal model
pred <-  predict(def_pr,newdata=cancer_tst)
predicted_pr[i] <- mean((cancer_tst$lpsa - pred)^2)
}
# retrieve the optimal number of variables for random forest
rf.opt.mtry<- def_rf$bestTune$mtry
# retrieve the optimal number of trees for boosting
ns.opt.n.trees<- round(def_bg$bestTune$n.trees,4)
# retrieve the optimal complexity for pruning
pr.opt.k<- def_pr$bestTune$cp
# retrive cv- test error from random forest, boosting, pruning
rf_cv_test_error <- round(mean(predicted_rf),4)
gb_cv_test_error <- round(mean(predicted_bg),4)
pr_cv_test_error <- round(mean(predicted_pr),4)
# fit the optimal boosting model
boosted <- gbm( lpsa~ ., data=cancer, distribution="gaussian",
n.trees=opt.ntrees, interaction.depth=4)
knitr::kable(summary(boosted, plotit = FALSE, order = TRUE))
# fit the optimal boosting model
boosted <- gbm( lpsa~ ., data=cancer, distribution="gaussian",
n.trees=opt.ntrees, interaction.depth=4)
knitr::kable(summary(boosted, plotit = FALSE, order = TRUE))
#| label: rf importance
#| echo: false
#| fig-cap: "The straight line represents the increase in prediction error (MSE), while the circle indicates the node purity (both when the predictor is included and excluded). The results align with previous decision trees: both lcavol and lweight are identified as significant predictors of the protein's level. However, an additional predictor, previously overlooked, such as svi (seminal vesicle invasion), has now emerged as influential. For instance, removing svi leads to an approximate 11% increase in MSE and a 15% increase in node impurity."
rf.cancer <- randomForest(lpsa ~ ., data = cancer, mtry = opt.mrty, importance = TRUE)
ImpData <- as.data.frame(importance(rf.cancer))
ImpData$Var.Names <- row.names(ImpData)
ggplot(ImpData, aes(x=Var.Names, y=`%IncMSE`)) +
geom_segment( aes(x=Var.Names, xend=Var.Names, y=0, yend=`%IncMSE`), color="skyblue") +
geom_point(aes(size = IncNodePurity), color="blue", alpha=0.6) +
theme_light() +
coord_flip() +
theme(
legend.position="bottom",
panel.grid.major.y = element_blank(),
panel.border = element_blank(),
axis.ticks.y = element_blank()
)
# fit the optimal boosting model
boosted <- gbm( lpsa~ ., data=cancer, distribution="gaussian",
n.trees=opt.ntrees, interaction.depth=4)
knitr::kable(summary(boosted, plotit = FALSE, order = TRUE))
set.seed(1)
# fit the optimal boosting model
boosted <- gbm( lpsa~ ., data=cancer, distribution="gaussian",
n.trees=opt.ntrees, interaction.depth=4)
knitr::kable(summary(boosted, plotit = FALSE, order = TRUE))
set.seed(1)
# fit the optimal boosting model
boosted <- gbm( lpsa~ ., data=cancer, distribution="gaussian",
n.trees=opt.ntrees, interaction.depth=4)
knitr::kable(summary(boosted, plotit = FALSE, order = TRUE))
ggplot(ImpData, aes(x=Var.Names, y=`%IncMSE`)) +
geom_segment( aes(x=Var.Names, xend=Var.Names, y=0, yend=`%IncMSE`), color="skyblue") +
geom_point(aes(size = IncNodePurity), color="blue", alpha=0.6) +
theme_light() +
coord_flip() +
theme(
legend.position="bottom",
panel.grid.major.y = element_blank(),
panel.border = element_blank(),
axis.ticks.y = element_blank()
)
importance(rf.cancer)
importance(rf.cancer)
ggplot(ImpData, aes(x=Var.Names, y=`%IncMSE`)) +
geom_segment( aes(x=Var.Names, xend=Var.Names, y=0, yend=`%IncMSE`), color="skyblue") +
geom_point(aes(size = IncNodePurity), color="blue", alpha=0.6) +
theme_light() +
coord_flip() +
theme(
legend.position="bottom",
panel.grid.major.y = element_blank(),
panel.border = element_blank(),
axis.ticks.y = element_blank()
)
# compute for each hyperparameter value the cv error
cv.mse.rf <- apply(rf.mse, FUN=mean, MARGIN = 2)
# return the optimal value of the hyperparameter and the lowest cv-error
opt.mrty <-which.min(cv.mse.rf)
min_val_rf <- round(min(cv.mse.rf),4)
#| label: rf importance
#| echo: false
#| fig-cap: "The straight line represents the increase in prediction error (MSE), while the circle indicates the node purity (both when the predictor is included and excluded). The results align with previous decision trees: both lcavol and lweight are identified as significant predictors of the protein's level. However, an additional predictor, previously overlooked, such as svi (seminal vesicle invasion), has now emerged as influential. For instance, removing svi leads to an approximate 9% increase in MSE and a 15% increase in node impurity."
set.seed(1)
rf.cancer <- randomForest(lpsa ~ ., data = cancer, mtry = opt.mrty, importance = TRUE)
ImpData <- as.data.frame(importance(rf.cancer))
ImpData$Var.Names <- row.names(ImpData)
ggplot(ImpData, aes(x=Var.Names, y=`%IncMSE`)) +
geom_segment( aes(x=Var.Names, xend=Var.Names, y=0, yend=`%IncMSE`), color="skyblue") +
geom_point(aes(size = IncNodePurity), color="blue", alpha=0.6) +
theme_light() +
coord_flip() +
theme(
legend.position="bottom",
panel.grid.major.y = element_blank(),
panel.border = element_blank(),
axis.ticks.y = element_blank()
)
importance(rf.cancer)
knitr::kable(summary(boosted, plotit = FALSE, order = TRUE))
ns.opt.n.trees<- round(def_bg$bestTune$n.trees,0)
ns.opt.n.trees
#| echo: true
#| output: false
set.seed(1)
# split the data into 5 folds
cancer_folds = createFolds(cancer$lpsa, k = 5, list = FALSE)
# set the traincontrol
cv_5 = trainControl(method = "cv",
number = 5,
search = "grid")
# collect the predict score got from CV.
predicted_rf = matrix(0, nrow=5, ncol = 1)
predicted_bg = matrix(0, nrow=5, ncol = 1)
predicted_pr = matrix(0, nrow=5, ncol = 1)
# set the grid for hyperparamenters' values
tune_grid_rf <- expand.grid(mtry = 1:7)
tune_grid_gb <- expand.grid(n.trees = seq(50,1000,length=10),interaction.depth = 3,shrinkage = 0.01,n.minobsinnode = 10)
tune_grid_pr <- expand.grid(cp = seq(0.5,10,length=5))
# outer loop
for(i in 1:5){
# split dataset into training set and test set
cancer_idx = which(cancer_folds == i)
cancer_trn = cancer[-cancer_idx,]
cancer_tst = cancer[cancer_idx,]
# inner loop for random forest
def_rf <-  train(
lpsa ~., data = cancer_trn,
method = "rf",
trControl = cv_5,
tuneGrid = tune_grid_rf
)
# collect the predict score based on random forest optimal model
pred <-  predict(def_rf,newdata=cancer_tst)
predicted_rf[i] <- mean((cancer_tst$lpsa - pred)^2)
# inner loop for boosted tree
def_bg <-  train(
lpsa ~., data = cancer_trn,
method = "gbm",
trControl = cv_5,
tuneGrid = tune_grid_gb
)
# collect the predict score based on boosted tree optimal model
pred <-  predict(def_bg,newdata=cancer_tst)
predicted_bg[i] <- mean((cancer_tst$lpsa - pred)^2)
# inner loop for cost-complexity decision tree
def_pr <-  train(
lpsa ~., data = cancer_trn,
method = "rpart",
trControl = cv_5,
tuneGrid = tune_grid_pr
)
# collect the predict score based on ost-complexity decision tree optimal model
pred <-  predict(def_pr,newdata=cancer_tst)
predicted_pr[i] <- mean((cancer_tst$lpsa - pred)^2)
}
# retrieve the optimal number of variables for random forest
rf.opt.mtry<- def_rf$bestTune$mtry
# retrieve the optimal number of trees for boosting
ns.opt.n.trees<- round(def_bg$bestTune$n.trees,0)
# retrieve the optimal complexity for pruning
pr.opt.k<- def_pr$bestTune$cp
# retrive cv- test error from random forest, boosting, pruning
rf_cv_test_error <- round(mean(predicted_rf),4)
gb_cv_test_error <- round(mean(predicted_bg),4)
pr_cv_test_error <- round(mean(predicted_pr),4)
#| echo: true
#| output: false
set.seed(1)
# split the data into 5 folds
cancer_folds = createFolds(cancer$lpsa, k = 5, list = FALSE)
# set the traincontrol
cv_5 = trainControl(method = "cv",
number = 5,
search = "grid")
# collect the predict score got from CV.
predicted_rf = matrix(0, nrow=5, ncol = 1)
predicted_bg = matrix(0, nrow=5, ncol = 1)
predicted_pr = matrix(0, nrow=5, ncol = 1)
# set the grid for hyperparamenters' values
tune_grid_rf <- expand.grid(mtry = 1:7)
tune_grid_gb <- expand.grid(n.trees = seq(50,1000,length=10),interaction.depth = 3,shrinkage = 0.01,n.minobsinnode = 10)
tune_grid_pr <- expand.grid(cp = seq(0.5,10,length=5))
# outer loop
for(i in 1:5){
# split dataset into training set and test set
cancer_idx = which(cancer_folds == i)
cancer_trn = cancer[-cancer_idx,]
cancer_tst = cancer[cancer_idx,]
# inner loop for random forest
def_rf <-  train(
lpsa ~., data = cancer_trn,
method = "rf",
trControl = cv_5,
tuneGrid = tune_grid_rf
)
# collect the predict score based on random forest optimal model
pred <-  predict(def_rf,newdata=cancer_tst)
predicted_rf[i] <- mean((cancer_tst$lpsa - pred)^2)
# inner loop for boosted tree
def_bg <-  train(
lpsa ~., data = cancer_trn,
method = "gbm",
trControl = cv_5,
tuneGrid = tune_grid_gb
)
# collect the predict score based on boosted tree optimal model
pred <-  predict(def_bg,newdata=cancer_tst)
predicted_bg[i] <- mean((cancer_tst$lpsa - pred)^2)
# inner loop for cost-complexity decision tree
def_pr <-  train(
lpsa ~., data = cancer_trn,
method = "rpart",
trControl = cv_5,
tuneGrid = tune_grid_pr
)
# collect the predict score based on ost-complexity decision tree optimal model
pred <-  predict(def_pr,newdata=cancer_tst)
predicted_pr[i] <- mean((cancer_tst$lpsa - pred)^2)
}
# retrieve the optimal number of variables for random forest
rf.opt.mtry<- def_rf$bestTune$mtry
# retrieve the optimal number of trees for boosting
ns.opt.n.trees<- round(def_bg$bestTune$n.trees,0)
# retrieve the optimal complexity for pruning
pr.opt.k<- def_pr$bestTune$cp
# retrive cv- test error from random forest, boosting, pruning
rf_cv_test_error <- round(mean(predicted_rf),4)
gb_cv_test_error <- round(mean(predicted_bg),4)
pr_cv_test_error <- round(mean(predicted_pr),4)
#| echo: true
#| output: false
#| code-fold: true
#| code
set.seed(1)
# split the data into 5 folds
cancer_folds = createFolds(cancer$lpsa, k = 5, list = FALSE)
# set the traincontrol
cv_5 = trainControl(method = "cv",
number = 5,
search = "grid")
# collect the predict score got from CV.
predicted_rf = matrix(0, nrow=5, ncol = 1)
predicted_bg = matrix(0, nrow=5, ncol = 1)
predicted_pr = matrix(0, nrow=5, ncol = 1)
# set the grid for hyperparamenters' values
tune_grid_rf <- expand.grid(mtry = 1:7)
tune_grid_gb <- expand.grid(n.trees = seq(50,1000,length=10),interaction.depth = 3,shrinkage = 0.01,n.minobsinnode = 10)
tune_grid_pr <- expand.grid(cp = seq(0.5,10,length=5))
# outer loop
for(i in 1:5){
# split dataset into training set and test set
cancer_idx = which(cancer_folds == i)
cancer_trn = cancer[-cancer_idx,]
cancer_tst = cancer[cancer_idx,]
# inner loop for random forest
def_rf <-  train(
lpsa ~., data = cancer_trn,
method = "rf",
trControl = cv_5,
tuneGrid = tune_grid_rf
)
# collect the predict score based on random forest optimal model
pred <-  predict(def_rf,newdata=cancer_tst)
predicted_rf[i] <- mean((cancer_tst$lpsa - pred)^2)
# inner loop for boosted tree
def_bg <-  train(
lpsa ~., data = cancer_trn,
method = "gbm",
trControl = cv_5,
tuneGrid = tune_grid_gb
)
# collect the predict score based on boosted tree optimal model
pred <-  predict(def_bg,newdata=cancer_tst)
predicted_bg[i] <- mean((cancer_tst$lpsa - pred)^2)
# inner loop for cost-complexity decision tree
def_pr <-  train(
lpsa ~., data = cancer_trn,
method = "rpart",
trControl = cv_5,
tuneGrid = tune_grid_pr
)
# collect the predict score based on ost-complexity decision tree optimal model
pred <-  predict(def_pr,newdata=cancer_tst)
predicted_pr[i] <- mean((cancer_tst$lpsa - pred)^2)
}
# retrieve the optimal number of variables for random forest
rf.opt.mtry<- def_rf$bestTune$mtry
# retrieve the optimal number of trees for boosting
ns.opt.n.trees<- round(def_bg$bestTune$n.trees,0)
# retrieve the optimal complexity for pruning
pr.opt.k<- def_pr$bestTune$cp
# retrive cv- test error from random forest, boosting, pruning
rf_cv_test_error <- round(mean(predicted_rf),4)
gb_cv_test_error <- round(mean(predicted_bg),4)
pr_cv_test_error <- round(mean(predicted_pr),4)
